Chatbot Advisor - WebApp with Docker, FastAPI, and Streamlit

This project implements an advisor chatbot that allows users to upload PDFs containing laws and regulations. The chatbot responds to user questions using a language model (LLM) based on Ollama and stores information in ChromaDB for semantic searches.

ğŸ“Œ Technologies Used

Python 3.11

FastAPI (Backend)

Streamlit (Web Interface)

ChromaDB (Vector Database)

Ollama (Language Model)

Docker & Docker Compose

ğŸš€ How to Use the Project

1ï¸âƒ£ Install Docker and Docker Compose

ğŸ”— Docker Installation Guide

2ï¸âƒ£ Clone the Repository

git clone https://github.com/your-repository/chatbot-legalista.git
cd chatbot-legalista

3ï¸âƒ£ Build and Start the Containers

docker compose up --build

The application will be available at:

Web Interface (Streamlit): http://localhost:8501

API Backend (FastAPI): http://localhost:8000

ğŸ“‚ Project Structure

chatbot-app/
â”‚â”€â”€ backend/
â”‚ â”‚â”€â”€ main.py # FastAPI API
â”‚ â”‚â”€â”€ process.py # PDF Processing
â”‚ â”‚â”€â”€ vector_store.py # Semantic Storage (ChromaDB)
â”‚ â”‚â”€â”€ chat.py # Communication with Ollama
â”‚â”€â”€ app.py # Streamlit Interface
â”‚â”€â”€ Dockerfile.backend # Backend Configuration
|â”€â”€ Dockerfile.streamlit # Frontend Configuration
â”‚â”€â”€ docker-compose.yml # Container Orchestration
â”‚â”€â”€ requirements.txt # Project Dependencies
|â”€â”€ entrypoint.sh # Script for running Ollama
|â”€â”€ readme.md

ğŸ› ï¸ How It Works

ğŸ”¹ PDF Upload

The user uploads a PDF file via Streamlit.

The backend (FastAPI) processes and extracts text from the PDF.

The text is converted into embeddings and stored in ChromaDB.

ğŸ”¹ Chatbot Query

The user asks a question in Streamlit.

The backend searches ChromaDB for relevant parts of the PDFs.

The retrieved elements are sent to Ollama, which generates a response.

The response is sent to the user via Streamlit.

ğŸ“¡ Communication Between Services

FastAPI communicates with:

ChromaDB (http://chromadb:8000) for context searches.

Ollama (http://ollama:11434) to generate responses.

Streamlit interacts with FastAPI to send questions and receive responses.

ğŸ›‘ Stopping the Containers

docker compose down

To monitor logs in real time:

docker compose logs -f

ğŸ“ Upcoming Features

ğŸ” User Authentication

ğŸ” Improved Semantic Search

ğŸ’¾ Persistence and Conversation History

If you have any questions or suggestions, feel free to contribute! ğŸš€ If you can't help, just make some noise, the important thing is to participate! ğŸ˜œ

ğŸ“– VersÃ£o em PortuguÃªs

Chatbot Conselheiro - WebApp com Docker, FastAPI e Streamlit

Este projeto implementa um chatbot conselheiro que permite o upload de PDFs com leis e regulamentos. O chatbot responde a perguntas do utilizador atravÃ©s de um modelo de linguagem (LLM) baseado no Ollama e guarda informaÃ§Ãµes em ChromaDB para buscas semÃ¢nticas.

ğŸ“Œ Tecnologias Utilizadas

Python 3.11

FastAPI (Backend)

Streamlit (Interface Web)

ChromaDB (Banco de dados vetorial)

Ollama (Modelo de linguagem)

Docker & Docker Compose

ğŸš€ Como utilizar o Projeto

1ï¸âƒ£ Instalar o Docker e Docker Compose

ğŸ”— Guia de InstalaÃ§Ã£o do Docker

2ï¸âƒ£ Clonar o RepositÃ³rio

git clone https://github.com/seu-repositorio/chatbot-legalista.git
cd chatbot-legalista

3ï¸âƒ£ Construir e Iniciar os Containers

docker compose up --build

A aplicaÃ§Ã£o estarÃ¡ disponÃ­vel em:

Interface Web (Streamlit): http://localhost:8501

API Backend (FastAPI): http://localhost:8000

ğŸ“‚ Estrutura do Projeto

chatbot-app/
â”‚â”€â”€ backend/
â”‚ â”‚â”€â”€ main.py # API FastAPI
â”‚ â”‚â”€â”€ process.py # Processamento de PDFs
â”‚ â”‚â”€â”€ vector_store.py # Armazenamento semÃ¢ntico (ChromaDB)
â”‚ â”‚â”€â”€ chat.py # ComunicaÃ§Ã£o com Ollama
â”‚â”€â”€ app.py # Interface Streamlit
â”‚â”€â”€ Dockerfile.backend # ConfiguraÃ§Ã£o do backend
|â”€â”€ Dockerfile.streamlit # ConfiguraÃ§Ã£o do frontend
â”‚â”€â”€ docker-compose.yml # OrquestraÃ§Ã£o dos containers
â”‚â”€â”€ requirements.txt # DependÃªncias do projeto
|â”€â”€ entrypoint.sh # Script para correr no Ollama
|â”€â”€ readme.md

ğŸ› ï¸ Como Funciona

ğŸ”¹ Upload de PDFs

O utilizador envia um arquivo PDF via Streamlit.

O backend (FastAPI) processa e extrai o texto do PDF.

O texto Ã© convertido em embeddings e armazenado no ChromaDB.

ğŸ”¹ Consulta ao Chatbot

O utilizador faz uma pergunta no Streamlit.

O backend procura no ChromaDB partes relevantes dos PDFs.

Os elementos sÃ£o enviados para o Ollama, que gera uma resposta.

A resposta Ã© enviada ao utilizador via Streamlit.

ğŸ“¡ ComunicaÃ§Ã£o entre ServiÃ§os

FastAPI comunica com:

ChromaDB (http://chromadb:8000) para pesquisas de contexto.

Ollama (http://ollama:11434) para gerar respostas.

Streamlit interage com o FastAPI para enviar perguntas e receber respostas.

ğŸ›‘ Parar os Containers

docker compose down

Para monitorizar logs em tempo real:

docker compose logs -f

ğŸ“ Funcionalidades a implementar brevemente

ğŸ” AutenticaÃ§Ã£o de Utilizadores

ğŸ” Melhorias na Busca SemÃ¢ntica

ğŸ’¾ PersistÃªncia e HistÃ³rico de Conversas

Se tiver dÃºvidas ou sugestÃµes, sinta-se Ã  vontade para contribuir! ğŸš€ Se nÃ£o puder ajudar, atrapalhe, o importante Ã© participar! ğŸ˜œ
