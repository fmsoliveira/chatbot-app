# Chatbot Conselheiro - WebApp com Docker, FastAPI e Streamlit

Este projeto implementa um chatbot conselheiro que permite o upload de PDFs com leis e regulamentos. O chatbot responde a perguntas do utilizador atravÃ©s de um modelo de linguagem (LLM) baseado no **Ollama** e guarda informaÃ§Ãµes em **ChromaDB** para buscas semÃ¢nticas.

## ğŸ“Œ Tecnologias Utilizadas

- **Python 3.11**
- **FastAPI** (Backend)
- **Streamlit** (Interface Web)
- **ChromaDB** (Banco de dados vetorial)
- **Ollama** (Modelo de linguagem)
- **Docker & Docker Compose**

---

## ğŸš€ Como utilizar o Projeto

### 1ï¸âƒ£ Instalar o Docker e Docker Compose

ğŸ”— [Guia de InstalaÃ§Ã£o do Docker](https://docs.docker.com/get-docker/)

### 2ï¸âƒ£ Clonar o RepositÃ³rio

```bash
git clone https://github.com/seu-repositorio/chatbot-legalista.git
cd chatbot-legalista
```

### 3ï¸âƒ£ Construir e Iniciar os Containers

```bash
docker compose up --build
```

A aplicaÃ§Ã£o estarÃ¡ disponÃ­vel em:

- **Interface Web (Streamlit):** [http://localhost:8501](http://localhost:8501)
- **API Backend (FastAPI):** [http://localhost:8000](http://localhost:8000)

---

## ğŸ“‚ Estrutura do Projeto

```
chatbot-app/
â”‚â”€â”€ backend/
â”‚   â”‚â”€â”€ main.py          # API FastAPI
â”‚   â”‚â”€â”€ process.py       # Processamento de PDFs
â”‚   â”‚â”€â”€ vector_store.py  # Armazenamento semÃ¢ntico (ChromaDB)
â”‚   â”‚â”€â”€ chat.py          # ComunicaÃ§Ã£o com Ollama
â”‚â”€â”€ app.py               # Interface Streamlit
â”‚â”€â”€ Dockerfile.backend   # ConfiguraÃ§Ã£o do backend
|â”€â”€ Dockerfile.streamlit # ConfiguraÃ§Ã£o do frontend
â”‚â”€â”€ docker-compose.yml   # OrquestraÃ§Ã£o dos containers
â”‚â”€â”€ requirements.txt     # DependÃªncias do projeto
|â”€â”€ entrypoint.sh        # script para correr no ollama
|â”€â”€ readme.md
```

---

## ğŸ› ï¸ Como Funciona

### ğŸ”¹ Upload de PDFs

1. O utilizador envia um arquivo PDF via **Streamlit**.
2. O **backend (FastAPI)** processa e extrai o texto do PDF.
3. O texto Ã© convertido em embeddings e armazenado no **ChromaDB**.

### ğŸ”¹ Consulta ao Chatbot

1. O utilizador faz uma pergunta no **Streamlit**.
2. O **backend** procura no **ChromaDB** partes relevantes dos PDFs.
3. Os elementos sÃ£o enviados para o **Ollama**, que gera uma resposta.
4. A resposta Ã© enviada ao utilizador via **Streamlit**.

---

## ğŸ“¡ ComunicaÃ§Ã£o entre ServiÃ§os

1. **FastAPI** comunica com:

   - **ChromaDB** (`http://chromadb:8000`) para pesquisas de contexto.
   - **Ollama** (`http://ollama:11434`) para gerar respostas.

2. **Streamlit** interage com o **FastAPI** para enviar perguntas e receber respostas.

---

## ğŸ›‘ Parar os Containers

```bash
docker compose down
```

Para monitorizar logs em tempo real:

```bash
docker compose logs -f
```

---

## ğŸ“ Funcionalidades a implementar brevemente

- ğŸ” **AutenticaÃ§Ã£o de Utilizadores**
- ğŸ” **Melhorias na Busca SemÃ¢ntica**
- ğŸ’¾ **PersistÃªncia e HistÃ³rico de Conversas**

Se tiver dÃºvidas ou sugestÃµes, sinta-se Ã  vontade para contribuir! ğŸš€ Se nÃ£o puder ajudar, atrapalhe, o importante Ã© participar! ğŸ˜œ
