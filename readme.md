# Chatbot Advisor - WebApp with Docker, FastAPI, and Streamlit

This project implements an advisor chatbot that allows users to upload PDFs containing laws and regulations. The chatbot responds to user questions using a **language model (LLM)** based on **Ollama** and stores information in **ChromaDB** for semantic searches.

## ğŸ“Œ Technologies Used

- **Python 3.11**
- **FastAPI** (Backend)
- **Streamlit** (Web Interface)
- **ChromaDB** (Vector Database)
- **Ollama** (Language Model)
- **Docker & Docker Compose**

---

## ğŸš€ How to Use the Project

### 1ï¸âƒ£ Install Docker and Docker Compose

ğŸ”— [Docker Installation Guide](https://docs.docker.com/get-docker/)

### 2ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-repository/chatbot-legalista.git
cd chatbot-legalista
```

### 3ï¸âƒ£ Build and Start the Containers

```bash
docker compose up --build
```

The application will be available at:

- **Web Interface (Streamlit):** [http://localhost:8501](http://localhost:8501)
- **API Backend (FastAPI):** [http://localhost:8000](http://localhost:8000)

---

## ğŸ“‚ Project Structure

```
chatbot-app/
â”‚â”€â”€ backend/
â”‚   â”‚â”€â”€ main.py          # FastAPI API
â”‚   â”‚â”€â”€ process.py       # PDF Processing
â”‚   â”‚â”€â”€ vector_store.py  # Semantic Storage (ChromaDB)
â”‚   â”‚â”€â”€ chat.py          # Communication with Ollama
â”‚â”€â”€ app.py               # Streamlit Interface
â”‚â”€â”€ Dockerfile.backend   # Backend Configuration
|â”€â”€ Dockerfile.streamlit # Frontend Configuration
â”‚â”€â”€ docker-compose.yml   # Container Orchestration
â”‚â”€â”€ requirements.txt     # Project Dependencies
|â”€â”€ entrypoint.sh        # Script for running Ollama
|â”€â”€ readme.md
```

---

## ğŸ› ï¸ How It Works

### ğŸ”¹ PDF Upload

1. The user uploads a PDF file via **Streamlit**.
2. The **backend (FastAPI)** processes and extracts text from the PDF.
3. The text is converted into embeddings and stored in **ChromaDB**.

### ğŸ”¹ Chatbot Query

1. The user asks a question in **Streamlit**.
2. The **backend** searches **ChromaDB** for relevant parts of the PDFs.
3. The retrieved elements are sent to **Ollama**, which generates a response.
4. The response is sent to the user via **Streamlit**.

---

## ğŸ“¡ Communication Between Services

1. **FastAPI** communicates with:

   - **ChromaDB** (`http://chromadb:8000`) for context searches.
   - **Ollama** (`http://ollama:11434`) to generate responses.

2. **Streamlit** interacts with **FastAPI** to send questions and receive responses.

---

## ğŸ›‘ Stopping the Containers

```bash
docker compose down
```

To monitor logs in real time:

```bash
docker compose logs -f
```

---

## ğŸ“ Upcoming Features

- ğŸ” **User Authentication**
- ğŸ” **Improved Semantic Search**
- ğŸ’¾ **Persistence and Conversation History**

If you have any questions or suggestions, feel free to contribute! ğŸš€ If you can't help, just make some noise, the important thing is to participate! ğŸ˜œ

---

## ğŸ“– VersÃ£o em PortuguÃªs

# Chatbot Conselheiro - WebApp com Docker, FastAPI e Streamlit

Este projeto implementa um chatbot conselheiro que permite o upload de PDFs com leis e regulamentos. O chatbot responde a perguntas do utilizador atravÃ©s de um **modelo de linguagem (LLM)** baseado no **Ollama** e guarda informaÃ§Ãµes em **ChromaDB** para buscas semÃ¢nticas.

## ğŸ“Œ Tecnologias Utilizadas

- **Python 3.11**
- **FastAPI** (Backend)
- **Streamlit** (Interface Web)
- **ChromaDB** (Banco de dados vetorial)
- **Ollama** (Modelo de linguagem)
- **Docker & Docker Compose**

---

## ğŸš€ Como utilizar o Projeto

### 1ï¸âƒ£ Instalar o Docker e Docker Compose

ğŸ”— [Guia de InstalaÃ§Ã£o do Docker](https://docs.docker.com/get-docker/)

### 2ï¸âƒ£ Clonar o RepositÃ³rio

```bash
git clone https://github.com/seu-repositorio/chatbot-legalista.git
cd chatbot-legalista
```

### 3ï¸âƒ£ Construir e Iniciar os Containers

```bash
docker compose up --build
```

A aplicaÃ§Ã£o estarÃ¡ disponÃ­vel em:

- **Interface Web (Streamlit):** [http://localhost:8501](http://localhost:8501)
- **API Backend (FastAPI):** [http://localhost:8000](http://localhost:8000)

---

## ğŸ“‚ Estrutura do Projeto

```
chatbot-app/
â”‚â”€â”€ backend/
â”‚   â”‚â”€â”€ main.py          # API FastAPI
â”‚   â”‚â”€â”€ process.py       # Processamento de PDFs
â”‚   â”‚â”€â”€ vector_store.py  # Armazenamento semÃ¢ntico (ChromaDB)
â”‚   â”‚â”€â”€ chat.py          # ComunicaÃ§Ã£o com Ollama
â”‚â”€â”€ app.py               # Interface Streamlit
â”‚â”€â”€ Dockerfile.backend   # ConfiguraÃ§Ã£o do backend
|â”€â”€ Dockerfile.streamlit # ConfiguraÃ§Ã£o do frontend
â”‚â”€â”€ docker-compose.yml   # OrquestraÃ§Ã£o dos containers
â”‚â”€â”€ requirements.txt     # DependÃªncias do projeto
|â”€â”€ entrypoint.sh        # Script para correr no Ollama
|â”€â”€ readme.md
```

---

## ğŸ› ï¸ Como Funciona

### ğŸ”¹ Upload de PDFs

1. O utilizador envia um arquivo PDF via **Streamlit**.
2. O **backend (FastAPI)** processa e extrai o texto do PDF.
3. O texto Ã© convertido em embeddings e armazenado no **ChromaDB**.

### ğŸ”¹ Consulta ao Chatbot

1. O utilizador faz uma pergunta no **Streamlit**.
2. O **backend** procura no **ChromaDB** partes relevantes dos PDFs.
3. Os elementos sÃ£o enviados para o **Ollama**, que gera uma resposta.
4. A resposta Ã© enviada ao utilizador via **Streamlit**.

---

## ğŸ“¡ ComunicaÃ§Ã£o entre ServiÃ§os

1. **FastAPI** comunica com:

   - **ChromaDB** (`http://chromadb:8000`) para pesquisas de contexto.
   - **Ollama** (`http://ollama:11434`) para gerar respostas.

2. **Streamlit** interage com o **FastAPI** para enviar perguntas e receber respostas.

---

## ğŸ›‘ Parar os Containers

```bash
docker compose down
```

Para monitorizar logs em tempo real:

```bash
docker compose logs -f
```

---

## ğŸ“ Funcionalidades a implementar brevemente

- ğŸ” **AutenticaÃ§Ã£o de Utilizadores**
- ğŸ” **Melhorias na Busca SemÃ¢ntica**
- ğŸ’¾ **PersistÃªncia e HistÃ³rico de Conversas**

Se tiver dÃºvidas ou sugestÃµes, sinta-se Ã  vontade para contribuir! ğŸš€ Se nÃ£o puder ajudar, atrapalhe, o importante Ã© participar! ğŸ˜œ
